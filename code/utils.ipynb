{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Processing dataframe with label"],"metadata":{"id":"U59pxjclrJQX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AnOWSs7mq71Z"},"outputs":[],"source":["def process_bbox(data):\n","  '''\n","    convert string list bbox to 4 columns\n","  '''\n","  data['bbox'] = data['bbox'].str.strip('[')\n","  data['bbox'] = data['bbox'].str.strip(']')\n","  data[['x','y','w','h']] = data['bbox'].str.split(',', expand=True).astype(float).astype(int)\n","  return data"]},{"cell_type":"markdown","source":["# IOU"],"metadata":{"id":"yhQpWMsHrljz"}},{"cell_type":"code","source":["# Convert x1, y1, x2, y2 -> x, y, w, h (top left -> bottom right)\n","def convert_corr(bbox):\n","  x1, y1,x2, y2 = bbox\n","  return [x1, y1, x2-x1, y2-y1]"],"metadata":{"id":"T4aP9RtRsZBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def iou(gt, pred):\n","\n","\t# bbox = x, y, w, h -> x, y, x+w, y+h\n","\n","\tgt_tmp = [gt[0], gt[1], gt[0] + gt[2], gt[1] + gt[3]]\n","\tpred_tmp = [pred[0], pred[1], pred[0] + gt[2], pred[1] + pred[3]]\n","\n","\txA = max(gt_tmp[0], pred_tmp[0])\n","\tyA = max(gt_tmp[1], pred_tmp[1])\n","\txB = min(gt_tmp[2], pred_tmp[2])\n","\tyB = min(gt_tmp[3], pred_tmp[3])\n","\n","\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\n","\tgtArea = (gt_tmp[2] - gt_tmp[0] + 1) * (gt_tmp[3] - gt_tmp[1] + 1)\n","\tpredArea = (pred_tmp[2] - pred_tmp[0] + 1) * (pred_tmp[3] - pred_tmp[1] + 1)\n","\n","\tiou = interArea / float(gtArea + predArea - interArea)\n","\treturn iou"],"metadata":{"id":"fA_PdkR2cTPU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image Processing"],"metadata":{"id":"pJ1zZZUtaP-q"}},{"cell_type":"markdown","source":["## Alignment"],"metadata":{"id":"UWx-THYeaqPa"}},{"cell_type":"code","source":["import math\n","from typing import Union\n","from PIL import Image\n","\n","def findEuclideanDistance(\n","    source_representation: Union[np.ndarray, list], test_representation: Union[np.ndarray, list]\n",") -> float:\n","    \"\"\"\n","    Find euclidean distance between 2 vectors\n","    Args:\n","        source_representation (numpy array or list)\n","        test_representation (numpy array or list)\n","    Returns\n","        distance\n","    \"\"\"\n","    if isinstance(source_representation, list):\n","        source_representation = np.array(source_representation)\n","\n","    if isinstance(test_representation, list):\n","        test_representation = np.array(test_representation)\n","\n","    euclidean_distance = source_representation - test_representation\n","    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n","    euclidean_distance = np.sqrt(euclidean_distance)\n","    return euclidean_distance\n","\n","def alignment_procedure(img: np.ndarray, left_eye: tuple, right_eye: tuple, nose: tuple):\n","    \"\"\"\n","    Alignma given face with respect to the left and right eye coordinates.\n","    Left eye is the eye appearing on the left (right eye of the person). Left top point is (0, 0)\n","    Args:\n","        img (numpy array): given image\n","        left_eye (tuple): left eye coordinates.\n","            Left eye is appearing on the left of image (right eye of the person)\n","        right_eye (tuple): right eye coordinates.\n","            Right eye is appearing on the right of image (left eye of the person)\n","        nose (tuple): coordinates of nose\n","    \"\"\"\n","\n","    left_eye_x, left_eye_y = left_eye\n","    right_eye_x, right_eye_y = right_eye\n","\n","    # -----------------------\n","    # find rotation direction\n","    if left_eye_y > right_eye_y:\n","        point_3rd = (right_eye_x, left_eye_y)\n","        direction = -1  # rotate same direction to clock\n","    else:\n","        point_3rd = (left_eye_x, right_eye_y)\n","        direction = 1  # rotate inverse direction of clock\n","\n","    # -----------------------\n","    # find length of triangle edges\n","\n","    a = findEuclideanDistance(np.array(left_eye), np.array(point_3rd))\n","    b = findEuclideanDistance(np.array(right_eye), np.array(point_3rd))\n","    c = findEuclideanDistance(np.array(right_eye), np.array(left_eye))\n","\n","    # -----------------------\n","    # apply cosine rule\n","    if b != 0 and c != 0:  # this multiplication causes division by zero in cos_a calculation\n","\n","        cos_a = (b * b + c * c - a * a) / (2 * b * c)\n","\n","        # PR15: While mathematically cos_a must be within the closed range [-1.0, 1.0],\n","        # floating point errors would produce cases violating this\n","        # In fact, we did come across a case where cos_a took the value 1.0000000169176173\n","        # which lead to a NaN from the following np.arccos step\n","        cos_a = min(1.0, max(-1.0, cos_a))\n","\n","        angle = np.arccos(cos_a)  # angle in radian\n","        angle = (angle * 180) / math.pi  # radian to degree\n","\n","        # -----------------------\n","        # rotate base image\n","\n","        if direction == -1:\n","            angle = 90 - angle\n","\n","        img = Image.fromarray(img)\n","        img = np.array(img.rotate(direction * angle))\n","\n","    # -----------------------\n","\n","    return img"],"metadata":{"id":"LtGDyNwDaONh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Detect and Extract face (use **InsightFace**)"],"metadata":{"id":"FbUKJuUDa9zE"}},{"cell_type":"code","source":["\"\"\"\n","import cv2\n","import numpy as np\n","import insightface\n","from insightface.app import FaceAnalysis\n","from insightface.data import get_image as ins_get_image\n","\n","app = FaceAnalysis(allowed_modules=['detection']) # enable detection model only\n","app.prepare(ctx_id=0, det_size=(640, 640))\n","\n","\"\"\"\n","\n","def extract_insight_face(app, img):\n","    faces = app.get(img)\n","    resp = []\n","\n","    expand_face_area = 2\n","    for face in faces:\n","      bbox = face['bbox']\n","      x = bbox[0]\n","      y = bbox[1]\n","      w = bbox[2]\n","      h = bbox[3]\n","\n","      # expand the facial area to be extracted and stay within img.shape limits\n","      x1 = max(0, x - int((w * expand_face_area) / 100))  # expand left\n","      y1 = max(0, y - int((h * expand_face_area) / 100))  # expand top\n","      x2 = min(img.shape[1], w + int((w * expand_face_area) / 100))  # expand right\n","      y2 = min(img.shape[0], h + int((h * expand_face_area) / 100))  # expand bottom\n","\n","      facial_img = img[int(y1):int(y2), int(x1):int(x2)]\n","\n","      #Face alignment\n","      landmarks = face['kps']\n","      left_eye = landmarks[1]\n","      right_eye = landmarks[0]\n","      nose = landmarks[2]\n","      # mouth_right = landmarks[\"mouth_right\"]\n","      # mouth_left = landmarks[\"mouth_left\"]\n","      facial_img = alignment_procedure(facial_img, right_eye, left_eye, nose)\n","\n","      result = {'facial_image': facial_img[:, :, ::-1],\n","              'bbox': convert_corr(bbox)}\n","\n","      resp.append(result)\n","\n","  return resp"],"metadata":{"id":"Joz7jvC_acD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector = MTCNN()\n","def extract_mtcnn(detector, img):\n","  faces = detector.detect_faces(img)\n","\n","  resp = []\n","\n","  expand_face_area = 2\n","  for face in faces:\n","    bbox = face['box']\n","    x = bbox[0]\n","    y = bbox[0]\n","    w = bbox[0] + bbox[2]\n","    h = bbox[0] + bbox[3]\n","\n","    # expand the facial area to be extracted and stay within img.shape limits\n","    x1 = max(0, x - int((w * expand_face_area) / 100))  # expand left\n","    y1 = max(0, y - int((h * expand_face_area) / 100))  # expand top\n","    x2 = min(img.shape[1], w + int((w * expand_face_area) / 100))  # expand right\n","    y2 = min(img.shape[0], h + int((h * expand_face_area) / 100))  # expand bottom\n","\n","    facial_img = img[int(y1):int(y2), int(x1):int(x2)]\n","\n","    #Face alignment\n","    landmarks = face['keypoints']\n","    left_eye = landmarks['left_eye']\n","    right_eye = landmarks['right_eye']\n","    nose = landmarks['nose']\n","    # mouth_right = landmarks[\"mouth_right\"]\n","    # mouth_left = landmarks[\"mouth_left\"]\n","    facial_img = alignment_procedure(facial_img, right_eye, left_eye, nose)\n","\n","    result = {'facial_image': facial_img[:, :, ::-1],\n","            'bbox': bbox}\n","\n","    resp.append(result)\n","\n","  return resp"],"metadata":{"id":"Nevc95pjkpjn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Detect and crop all images in folder"],"metadata":{"id":"inkNEOgubUf5"}},{"cell_type":"code","source":["def read_image(filename):\n","    dir_img = f'/content/drive/MyDrive/AI_HACKATHON_NEWBEES/data_processed/train/{filename}'\n","    img = cv2.imread(dir_img)\n","    return img"],"metadata":{"id":"84yWbw4fcBc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 500\n","num_batches = len(noface_files) // batch_size + (len(noface_files) % batch_size > 0)"],"metadata":{"id":"-arOUuLebwjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_folder_image(img_list, batch_size = 500):\n","  \"\"\"\n","  Function detect face + alignment -> crop face -> save\n","  Args:\n","    img_list: List image file name\n","    batch_size: Number of images processed in 1 batch\n","  \"\"\"\n","\n","  num_batches = len(img_list) // batch_size + (len(img_list) % batch_size > 0)\n","\n","  for batch_index in range(num_batches):\n","    print(\"-------------------------------------------\")\n","    print(f\"Processing batch {batch_index}\")\n","\n","    start_index = batch_index * batch_size\n","    end_index = min((batch_index + 1) * batch_size, len(img_list))\n","\n","    # Lấy batch dữ liệu từ list file\n","    batch_data = img_list[start_index:end_index]\n","    count = 0\n","    count_zero = 0\n","    for filename in batch_data:\n","      img = read_image(filename)\n","      result = extract_insight_face(img)\n","\n","      for i, face in enumerate(result):\n","        if len(result) == 0:\n","          count_zero += 1\n","        if len(result) != 1:\n","          print(f'File {filename} detected {len(result)} face(s).')\n","\n","        # Resize\n","        face['facial_image'] = cv2.resize(face, (256,256))\n","\n","        # Save\n","        if i > 0:\n","          filename = f'{i}_' + filename\n","\n","        save_file_name = f'/content/drive/MyDrive/AI_HACKATHON_NEWBEES/data_processed/p/{filename}'\n","        try:\n","          if not os.path.exists(save_file_name):\n","              cv2.imwrite(save_file_name, face[:, :, ::-1])\n","          else:\n","              print(f'File {save_file_name} existed.')\n","\n","        except Exception as e:\n","          print(f'Error when save file {filename}: {e}')\n","\n","        count += 1\n","\n","    print(f\"Finish batch {batch_index}.\")\n","    print(f\"Cropped {count} files.\")\n","    print(f\"Number of images cannot detect any face: {count_zero}\")"],"metadata":{"id":"dBcSz_MtbTe2"},"execution_count":null,"outputs":[]}]}